{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import psutil\n",
    "import pickle\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "import librosa\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "\n",
    "import torch as torch\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = Path('/kaggle/input/')\n",
    "WORKING_PATH = Path('/kaggle/working/')\n",
    "\n",
    "NOISY_PATH   = INPUT_PATH/'freesound-audio-tagging-2019/train_noisy'\n",
    "CURATED_PATH = INPUT_PATH/'freesound-audio-tagging-2019/train_curated'\n",
    "TEST_PATH   = INPUT_PATH/'freesound-audio-tagging-2019/test'\n",
    "PICKLE_PATH = WORKING_PATH/'pickles'\n",
    "MODEL_PATH = WORKING_PATH/'models'\n",
    "\n",
    "PICKLE_PATH.mkdir(exist_ok=True)\n",
    "MODEL_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_slice_len = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEDenseLayer(nn.Module):\n",
    "    def __init__(self, nf_in, nf_add):\n",
    "        self.nf_in, self.nf_add = nf_in, nf_add\n",
    "        super().__init__()\n",
    "        self.dense_layers=nn.Sequential(\n",
    "            nn.BatchNorm2d(nf_in),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=nf_in, out_channels=nf_in, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(nf_in),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=nf_in, out_channels=nf_add, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "        )\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.se_layers = nn.Sequential(\n",
    "            nn.Linear(nf_add, nf_add//2, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(nf_add//2, nf_add, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        d = self.dense_layers(x)\n",
    "\n",
    "        b, f, _, _ = d.size()\n",
    "        se = self.avg_pool(d).view(b,f)\n",
    "        se = self.se_layers(se).view(b,f,1,1)\n",
    "        se = d * se.expand_as(d)\n",
    "        \n",
    "        return torch.cat([x, se], 1)\n",
    "\n",
    "class SEDenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.first_conv = nn.Conv2d(in_channels=1, out_channels=15, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.se_dense_layers = nn.Sequential(\n",
    "            SEDenseLayer(16,16),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(32,32),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(64,64),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(128,128),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(256,256),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(512,512),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(512+512,512),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(512+512+512,512),\n",
    "            nn.MaxPool2d(2)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.linears = nn.ModuleList([\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80)\n",
    "        ])\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = torch.cat([x,self.first_conv(x)],1)\n",
    "        \n",
    "        d = self.se_dense_layers(y).squeeze(dim=3).squeeze(dim=2)\n",
    "        \n",
    "        linear_outs = []\n",
    "        for l in self.linears:\n",
    "            linear_outs.append(l(d))\n",
    "            \n",
    "        mean = torch.mean(torch.stack(linear_outs),dim=0)\n",
    "        \n",
    "        return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    \"\"\"Calculate precisions for each true class for a single sample.\n",
    "\n",
    "    Args:\n",
    "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "    Returns:\n",
    "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "        classes.\n",
    "    \"\"\"\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "    # Only calculate precisions if there are some true classes.\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "    # Retrieval list of classes for this sample.\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "    # Which of these is a true label?\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "    # Num hits for every truncated retrieval list.\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "\n",
    "    Arguments:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "        of presence of that class in that sample.\n",
    "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "        test's real-valued score for each class for each sample.\n",
    "\n",
    "    Returns:\n",
    "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
    "        class.\n",
    "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
    "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
    "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "    \"\"\"\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    # Space to store a distinct precision value for each class on each sample.\n",
    "    # Only the classes that are true for each sample will be filled in.\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = (\n",
    "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                  truth[sample_num, :]))\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "            precision_at_hits)\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "    # a particular class.\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "    return per_class_lwlrap, weight_per_class\n",
    "\n",
    "\n",
    "# Wrapper for fast.ai library - thanks @daisukelab\n",
    "def lwlrap(scores, truth, **kwargs):\n",
    "    score, weight = calculate_per_class_lwlrap(to_np(truth), to_np(scores))\n",
    "    return torch.Tensor([(score * weight).sum()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "mem_dic = manager.dict()\n",
    "\n",
    "\n",
    "def wav_to_spec(fn, slice_len = 2, slice_count=1, sr = 44100, n_mels = 256, fmin =20):\n",
    "\n",
    "    #set melspectrogram parameters to achieve a output size of n_mels, n_mels per slice_len seconds\n",
    "    hop_length   = int(sr/(n_mels/slice_len)) # ensures slice_len seconds per height\n",
    "    fmax         = sr//2\n",
    "    \n",
    "    pickle_file = Path(PICKLE_PATH/(Path(fn).parent.name + '_' + Path(fn).name +'.pkl'))\n",
    "    \n",
    "    pcen, pcen_pickle = None, None\n",
    "    \n",
    "    assert_equality = False\n",
    "    \n",
    "    if str(fn) in mem_dic:\n",
    "        pcen = mem_dic[str(fn)]\n",
    "\n",
    "    mem = psutil.virtual_memory().percent\n",
    "    \n",
    "    disk = shutil.disk_usage(\"/kaggle/working\").free/1e6\n",
    "\n",
    "    \n",
    "    if (not str(fn) in mem_dic) and pickle_file.exists():\n",
    "        with open(pickle_file, 'rb') as pf:\n",
    "            if assert_equality:\n",
    "                pcen_pickle = pickle.load(pf)  \n",
    "            else:\n",
    "                pcen = pickle.load(pf)\n",
    "                if mem < 90:\n",
    "                    mem_dic[str(fn)] = pcen\n",
    "    \n",
    "\n",
    "    if (not str(fn) in mem_dic) and ((not pickle_file.exists()) or assert_equality):\n",
    "        \n",
    "        y       = librosa.effects.trim(librosa.load(fn , sr)[0])[0]\n",
    "\n",
    "        mels    = librosa.feature.melspectrogram(y, \n",
    "                                                     sr=sr,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_fft=n_mels*20,\n",
    "                                                     fmin=fmin,\n",
    "                                                     fmax=fmax).astype(np.float32)\n",
    "\n",
    "        pcen = librosa.core.pcen(mels, \n",
    "                                        sr=sr,\n",
    "                                        hop_length=hop_length,\n",
    "                                        gain = 0.6,\n",
    "                                        bias = 0.1,\n",
    "                                        power = 0.2,\n",
    "                                        time_constant = 0.4,\n",
    "                                        eps=1e-9\n",
    "                                       )\n",
    "        \n",
    "        if mem < 90:\n",
    "            mem_dic[str(fn)] = pcen\n",
    "        \n",
    "        if assert_equality:\n",
    "            print(f'checking pickle {fn}')\n",
    "            if not np.allclose(pcen_pickle, pcen, rtol=1e-7,atol=1e-11,equal_nan=True):\n",
    "                print(f'{fn} new mels does not match pickle')\n",
    "        \n",
    "        if not pickle_file.exists() and disk > 500 and mem > 90:\n",
    "            with open(pickle_file, 'wb') as pf:\n",
    "                pickle.dump(pcen, pf)\n",
    "    \n",
    "    if random.random() < 0.001 :\n",
    "        print(f'disk free: {disk} mem used: {mem}')\n",
    "    \n",
    "    out_width = n_mels*slice_count\n",
    "    \n",
    "    pcen_len = pcen.shape[1]\n",
    "    \n",
    "    if pcen_len < out_width:\n",
    "        offset = random.randint(0, out_width-pcen_len)\n",
    "        cropped_padded = np.pad(pcen, ((0,0),(offset, (out_width-pcen_len)- offset)), 'constant')\n",
    "    else:\n",
    "        offset = random.randint(0, pcen_len-out_width)\n",
    "        cropped_padded = pcen[:,offset:offset+out_width]\n",
    "    \n",
    "    return cropped_padded\n",
    "\n",
    "def open_wav_image(fn, convert_mode, after_open)->Image:\n",
    "    melspec = wav_to_spec(fn, slice_len = g_slice_len, slice_count=1, sr = 44100, n_mels = 256, fmin =0)\n",
    "    return Image(torch.Tensor(melspec).unsqueeze(0))\n",
    "\n",
    "vision.data.open_image = open_wav_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_from_fn(fn, k):\n",
    "    random.seed(Path(fn).stem.encode())\n",
    "    return random.choice(range(k))\n",
    "\n",
    "k=3\n",
    "\n",
    "def valid_fn(fn, k, validation_fold):\n",
    "    return (validation_fold == fold_from_fn(fn, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy_df   = pd.read_csv(INPUT_PATH/'freesound-audio-tagging-2019/train_noisy.csv')\n",
    "train_curated_df = pd.read_csv(INPUT_PATH/'freesound-audio-tagging-2019/train_curated.csv')\n",
    "\n",
    "train_noisy_df['noisy_curated']   = 'noisy'\n",
    "train_curated_df['noisy_curated'] = 'curated'\n",
    "\n",
    "train_noisy_df['fname_path']      = str(NOISY_PATH)  +\"/\"+train_noisy_df.fname\n",
    "train_curated_df['fname_path']    = str(CURATED_PATH)+\"/\"+train_curated_df.fname\n",
    "\n",
    "train_combined_df = pd.concat([train_curated_df, train_noisy_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basic_train import _loss_func2activ\n",
    "\n",
    "def no_flip_tta_only(learn:Learner, ds_type:DatasetType=DatasetType.Valid, scale:float=1.35) -> Iterator[List[Tensor]]:\n",
    "    \"Computes the outputs for several augmented inputs for TTA\"\n",
    "    dl = learn.dl(ds_type)\n",
    "    ds = dl.dataset\n",
    "    old = ds.tfms\n",
    "    augm_tfm = [o for o in learn.data.train_ds.tfms if o.tfm not in\n",
    "               (crop_pad, flip_lr, dihedral, zoom)]\n",
    "    try:\n",
    "        pbar = master_bar(range(8))\n",
    "        for i in pbar:\n",
    "            row = 1 if i&1 else 0\n",
    "            col = 1 if i&2 else 0\n",
    "            flip = False\n",
    "            d = {'row_pct':row, 'col_pct':col, 'is_random':False}\n",
    "            tfm = [*augm_tfm, zoom(scale=scale, **d), crop_pad(**d)]\n",
    "            #if flip: tfm.append(flip_lr(p=1.))\n",
    "            ds.tfms = tfm\n",
    "            yield get_preds(learn.model, dl, pbar=pbar, activ=_loss_func2activ(learn.loss_func))[0]\n",
    "    finally: ds.tfms = old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_noisy_fold_0_lwlrap_0.816.pkl  dir_noisy_fold_3_lwlrap_0.802.pkl\r\n",
      "dir_noisy_fold_1_lwlrap_0.807.pkl  dir_noisy_fold_4_lwlrap_0.788.pkl\r\n",
      "dir_noisy_fold_2_lwlrap_0.81.pkl   dir_noisy_fold_5_lwlrap_0.805.pkl\r\n"
     ]
    }
   ],
   "source": [
    "ls ../input/6foldnoisydirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkls = ['dir_noisy_fold_0_lwlrap_0.816.pkl',\n",
    "              'dir_noisy_fold_3_lwlrap_0.802.pkl',\n",
    "              'dir_noisy_fold_1_lwlrap_0.807.pkl',\n",
    "              'dir_noisy_fold_4_lwlrap_0.788.pkl',\n",
    "              'dir_noisy_fold_2_lwlrap_0.81.pkl',\n",
    "              'dir_noisy_fold_5_lwlrap_0.805.pkl']\n",
    "pred_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk free: 4938.051584 mem used: 29.1\n",
      "disk free: 4938.051584 mem used: 29.1\n",
      "disk free: 4938.051584 mem used: 29.1\n",
      "disk free: 4938.051584 mem used: 29.1\n",
      "disk free: 4938.051584 mem used: 29.1\n",
      "disk free: 4938.051584 mem used: 29.1\n",
      "disk free: 4938.051584 mem used: 29.1\n"
     ]
    }
   ],
   "source": [
    "for mdl in model_pkls:\n",
    "    test = ImageList.from_folder(TEST_PATH, extensions='.wav')\n",
    "    learn = load_learner(INPUT_PATH/'6foldnoisydirected', mdl, test=test)\n",
    "    learn.model_dir = MODEL_PATH\n",
    "    learn.save('weights')\n",
    "    learn.model=SEDenseNet().cuda()\n",
    "    learn.load('weights')\n",
    "    os.remove(MODEL_PATH/'weights.pth')\n",
    "    \n",
    "    learn.data.batch_size = 50\n",
    "    learn.tta_only = partial(no_flip_tta_only,learn=learn)\n",
    "\n",
    "    preds, _ = learn.TTA(scale=1.1, ds_type=DatasetType.Test)\n",
    "    pred_list.append(preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned_model_fold_0.pkl  finetuned_model_fold_3.pkl\r\n",
      "finetuned_model_fold_1.pkl  finetuned_model_fold_4.pkl\r\n",
      "finetuned_model_fold_2.pkl  finetuned_model_fold_5.pkl\r\n"
     ]
    }
   ],
   "source": [
    "ls ../input/curatedthencombined6fold/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkls = ['finetuned_model_fold_0.pkl',\n",
    "              'finetuned_model_fold_3.pkl',\n",
    "              'finetuned_model_fold_1.pkl',\n",
    "              'finetuned_model_fold_4.pkl',\n",
    "              'finetuned_model_fold_2.pkl',\n",
    "              'finetuned_model_fold_5.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk free: 4938.047488 mem used: 29.1\n",
      "disk free: 4938.047488 mem used: 29.2\n",
      "disk free: 4938.047488 mem used: 29.2\n",
      "disk free: 4938.047488 mem used: 29.2\n",
      "disk free: 4938.047488 mem used: 29.1\n",
      "disk free: 4938.047488 mem used: 29.2\n",
      "disk free: 4938.047488 mem used: 29.2\n",
      "disk free: 4938.047488 mem used: 29.1\n"
     ]
    }
   ],
   "source": [
    "for mdl in model_pkls:\n",
    "    test = ImageList.from_folder(TEST_PATH, extensions='.wav')\n",
    "    learn = load_learner(INPUT_PATH/'curatedthencombined6fold', mdl, test=test)\n",
    "    learn.model_dir = MODEL_PATH\n",
    "    learn.save('weights')\n",
    "    learn.model=SEDenseNet().cuda()\n",
    "    learn.load('weights')\n",
    "    os.remove(MODEL_PATH/'weights.pth')\n",
    "    \n",
    "    learn.data.batch_size = 50\n",
    "    learn.tta_only = partial(no_flip_tta_only,learn=learn)\n",
    "\n",
    "    preds, _ = learn.TTA(scale=1.1, ds_type=DatasetType.Test)\n",
    "    pred_list.append(preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_preds = torch.stack(pred_list).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = [i.name for i in learn.data.test_ds.items]\n",
    "\n",
    "scores_dic = {learn.data.classes[i]: mean_preds.numpy()[:,i] for i in range(mean_preds.shape[1])}\n",
    "\n",
    "submission_df = pd.DataFrame({'fname':test_names, **scores_dic})\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r pickles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
