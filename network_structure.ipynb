{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network structure\n",
    "\n",
    "The idea here is to attempt to replicate the approach of the winners of the 2018 competition. The technical report is here:\n",
    "http://dcase.community/documents/challenge2018/technical_reports/DCASE2018_Jeong_102.pdf\n",
    "\n",
    "\n",
    "Their implementation here:\n",
    "https://github.com/finejuly/dcase2018_task2_cochlearai\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "<img src=\"images/high_level_arch.png\" width=\"25%\"/><img src=\"images/block_arch.png\" width=\"70%\"/>\n",
    "\n",
    "where the SE architecture is the Squeeze and Exitation block described here: https://arxiv.org/abs/1709.01507\n",
    "<img src=\"images/se_arch.png\" width=\"70%\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import psutil\n",
    "import pickle\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "import librosa\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "\n",
    "import torch as torch\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The conda.compat module is deprecated and will be removed in a future release.\n",
      "WARNING: The conda.compat module is deprecated and will be removed in a future release.\n",
      "usage: conda-env [-h] {create,export,list,remove,update} ...\n",
      "\n",
      "positional arguments:\n",
      "  {create,export,list,remove,update}\n",
      "    create              Create an environment based on an environment file\n",
      "    export              Export a given environment\n",
      "    list                List the Conda environments\n",
      "    remove              Remove an environment\n",
      "    update              Update the current environment based on environment\n",
      "                        file\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            Show this help message and exit.\n",
      "\n",
      "conda commands available from other packages:\n",
      "  build\n",
      "  convert\n",
      "  debug\n",
      "  develop\n",
      "  env\n",
      "  index\n",
      "  inspect\n",
      "  metapackage\n",
      "  render\n",
      "  server\n",
      "  skeleton\n",
      "  verify\n"
     ]
    }
   ],
   "source": [
    "!conda env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-84c6fab5f56b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b23ca1e47a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSEDenseLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnf_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnf_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnf_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnf_add\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         self.dense_layers=nn.Sequential(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class SEDenseLayer(nn.Module):\n",
    "    def __init__(self, nf_in, nf_add):\n",
    "        self.nf_in, self.nf_add = nf_in, nf_add\n",
    "        super().__init__()\n",
    "        self.dense_layers=nn.Sequential(\n",
    "            nn.BatchNorm2d(nf_in),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=nf_in, out_channels=nf_in, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(nf_in),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=nf_in, out_channels=nf_add, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "        )\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.se_layers = nn.Sequential(\n",
    "            nn.Linear(nf_add, nf_add//2, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(nf_add//2, nf_add, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        d = self.dense_layers(x)\n",
    "\n",
    "        b, f, _, _ = d.size()\n",
    "        se = self.avg_pool(d).view(b,f)\n",
    "        se = self.se_layers(se).view(b,f,1,1)\n",
    "        se = d * se.expand_as(d)\n",
    "        \n",
    "        return torch.cat([x, se], 1)\n",
    "\n",
    "class SEDenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.first_conv = nn.Conv2d(in_channels=1, out_channels=15, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.se_dense_layers = nn.Sequential(\n",
    "            SEDenseLayer(16,16),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(32,32),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(64,64),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(128,128),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(256,256),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(512,512),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(512+512,512),\n",
    "            nn.MaxPool2d(2),\n",
    "            SEDenseLayer(512+512+512,512),\n",
    "            nn.MaxPool2d(2)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.linears = nn.ModuleList([\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80),\n",
    "            nn.Linear(2048,80)\n",
    "        ])\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = torch.cat([x,self.first_conv(x)],1)\n",
    "        \n",
    "        d = self.se_dense_layers(y).squeeze(dim=3).squeeze(dim=2)\n",
    "        \n",
    "        linear_outs = []\n",
    "        for l in self.linears:\n",
    "            linear_outs.append(l(d))\n",
    "            \n",
    "        mean = torch.mean(torch.stack(linear_outs),dim=0)\n",
    "        \n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
